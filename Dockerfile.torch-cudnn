# --------------------------------------------------------------------
# PyTorch 2.1.0 (from source) for ARM64 + CUDA 12.3 (Ubuntu 22.04)
# WITH cuDNN support
# NumPy pinned to 1.26.x to satisfy PyTorch 2.1's C-API usage.
# --------------------------------------------------------------------
FROM nvidia/cuda:12.3.2-devel-ubuntu22.04

RUN uname -m
ENV DEBIAN_FRONTEND=noninteractive TZ=UTC

# Base toolchain and deps
RUN apt-get update && apt-get install -y --no-install-recommends \
    git ca-certificates curl wget pkg-config \
    build-essential g++ gcc make ccache \
    python3 python3-dev python3-pip python3-venv \
    cmake ninja-build \
    libopenblas-dev libffi-dev libssl-dev \
    libprotobuf-dev protobuf-compiler \
    libuv1-dev zlib1g-dev libjpeg-dev \
 && rm -rf /var/lib/apt/lists/*

# ---- NCCL: install only if missing (avoid "held packages" upgrade) ----
RUN set -eux; \
    if dpkg -s libnccl-dev >/dev/null 2>&1 && dpkg -s libnccl2 >/dev/null 2>&1; then \
        echo "NCCL present, skipping install"; \
    else \
        apt-get update; \
        apt-get install -y --no-install-recommends --allow-change-held-packages libnccl2 libnccl-dev || true; \
        dpkg -s libnccl-dev >/dev/null 2>&1 || echo "WARNING: libnccl-dev not confirmed installed (continuing)"; \
        dpkg -s libnccl2 >/dev/null 2>&1 || echo "WARNING: libnccl2 not confirmed installed (continuing)"; \
        rm -rf /var/lib/apt/lists/*; \
    fi

# ---- cuDNN: Install for CUDA 12.x (targeting cuDNN 8.9.x for PyTorch 2.1) ----
# Check what's available for arm64, fall back gracefully if version mismatch
RUN set -eux; \
    apt-get update; \
    # Try to install cuDNN 8 for CUDA 12
    apt-get install -y --no-install-recommends \
        libcudnn8 libcudnn8-dev || \
    # If that fails, try without version constraint
    apt-get install -y --no-install-recommends \
        libcudnn-dev libcudnn || true; \
    # Verify installation
    if [ -f /usr/include/cudnn.h ] || [ -f /usr/local/cuda/include/cudnn.h ]; then \
        echo "cuDNN headers found"; \
        grep CUDNN_MAJOR /usr/include/cudnn*.h /usr/local/cuda/include/cudnn*.h 2>/dev/null || echo "cuDNN version check skipped"; \
    else \
        echo "WARNING: cuDNN headers not found - build may proceed without cuDNN"; \
    fi; \
    rm -rf /var/lib/apt/lists/*

# Python tooling
RUN python3 -m pip install --upgrade pip wheel setuptools

# Build env
ENV CUDA_HOME=/usr/local/cuda
ENV USE_CUDA=1 \
    USE_CUDNN=1 \
    USE_NCCL=1 \
    USE_MKLDNN=0 \
    BUILD_TEST=0

# Explicitly help CMake find cuDNN (in case it's not in standard locations)
ENV CUDNN_LIBRARY=/usr/lib/aarch64-linux-gnu \
    CUDNN_INCLUDE_DIR=/usr/include

# H100 / Hopper; keep PTX for forward-compat
ENV TORCH_CUDA_ARCH_LIST="9.0+PTX"
ARG MAX_JOBS=8
ENV MAX_JOBS=${MAX_JOBS}

# ---- Pin NumPy 1.26.x everywhere via constraints ----
ARG NUMPY_PIN=1.26.4
RUN printf "numpy==%s\n" "$NUMPY_PIN" > /tmp/constraints.txt

# ---- Get & build PyTorch 2.1.0 ----
WORKDIR /workspace
ARG PYTORCH_REF=v2.1.0
RUN git clone --recursive --branch ${PYTORCH_REF} https://github.com/pytorch/pytorch.git

WORKDIR /workspace/pytorch
RUN git submodule sync && git submodule update --init --recursive

# Install PyTorch's Python requirements but constrain NumPy to 1.26.x
RUN python3 -m pip install -r requirements.txt -c /tmp/constraints.txt

# Common extras (also constrained)
RUN python3 -m pip install \
    typing_extensions filelock sympy networkx jinja2 fsspec \
    -c /tmp/constraints.txt

# Ensure the NumPy pin is active (prevents accidental upgrade by transitive deps)
RUN python3 -m pip install "numpy==${NUMPY_PIN}" --force-reinstall

# Build the wheel
RUN python3 setup.py bdist_wheel
RUN python3 -m pip install --no-cache-dir dist/torch-*.whl -c /tmp/constraints.txt

# Don't run from inside the repo when importing torch
WORKDIR /opt

# Verification with cuDNN check
RUN python3 - <<'PY'
import torch, subprocess, shlex, numpy as np
print("Torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
print("cuDNN enabled:", torch.backends.cudnn.enabled)
print("cuDNN version:", torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else "N/A")
try:
    out = subprocess.check_output(shlex.split("nvcc --version")).decode()
    print([l for l in out.splitlines() if "release" in l][0])
except Exception as e:
    print("nvcc check failed:", e)
print("GPU count:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("GPU 0:", torch.cuda.get_device_name(0))
print("NumPy:", np.__version__)
PY

WORKDIR /workspace